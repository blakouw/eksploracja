"""
MODUÅ TESTOWANIA HIPOTEZ
Testowanie trzech hipotez badawczych z rÃ³Å¼nymi zmiennymi zaleÅ¼nymi
"""

import pandas as pd
import numpy as np
from scipy import stats
from scipy.stats import pearsonr, ttest_ind
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import r2_score, accuracy_score, roc_auc_score, classification_report
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier

class HypothesisTesting:
    """Klasa do testowania trzech hipotez badawczych"""

    def __init__(self, df_analysis):
        self.df = df_analysis

        # Definicje hipotez
        self.hypotheses = {
            'h1': {
                'title': 'Wiek pacjenta jest gÅ‚Ã³wnym predyktorem poziomu troponiny',
                'dependent': 'Troponin',
                'independent': ['Age', 'Gender', 'Heart rate'],
                'type': 'regression',
                'description': 'Analiza regresyjna - czy wiek, pÅ‚eÄ‡ i tÄ™tno przewidujÄ… poziom troponiny'
            },
            'h2': {
                'title': 'PÅ‚eÄ‡ determinuje poziom ciÅ›nienia skurczowego',
                'dependent': 'Systolic blood pressure',
                'independent': ['Gender', 'Age', 'Blood sugar'],
                'type': 'regression',
                'description': 'Analiza regresyjna - czy pÅ‚eÄ‡, wiek i cukier przewidujÄ… ciÅ›nienie'
            },
            'h3': {
                'title': 'ZawaÅ‚ serca moÅ¼na przewidzieÄ‡ na podstawie biomarkerÃ³w',
                'dependent': 'Result_Binary',
                'independent': ['Troponin', 'CK-MB', 'Heart rate'],
                'type': 'classification',
                'description': 'Analiza klasyfikacyjna - czy biomarkery przewidujÄ… zawaÅ‚'
            }
        }

        self.results = {}

    def test_all_hypotheses(self):
        """Testuje wszystkie trzy hipotezy"""

        print("\n" + "=" * 80)
        print("TESTOWANIE HIPOTEZ BADAWCZYCH")
        print("=" * 80)

        # Testuj kaÅ¼dÄ… hipotezÄ™
        for hyp_id in ['h1', 'h2', 'h3']:
            print(f"\n{'='*60}")
            print(f"HIPOTEZA {hyp_id.upper()}")
            print(f"{'='*60}")

            hyp = self.hypotheses[hyp_id]
            print(f"ğŸ“Œ {hyp['title']}")
            print(f"ğŸ“Š {hyp['description']}")
            print(f"ğŸ¯ Zmienna zaleÅ¼na: {hyp['dependent']}")
            print(f"ğŸ“ˆ Zmienne niezaleÅ¼ne: {', '.join(hyp['independent'])}")

            if hyp['type'] == 'regression':
                result = self._test_regression_hypothesis(hyp_id, hyp)
            else:
                result = self._test_classification_hypothesis(hyp_id, hyp)

            self.results[hyp_id] = result

            # WyÅ›wietl wyniki
            self._display_hypothesis_results(hyp_id, result)

        # Podsumowanie wszystkich hipotez
        self._create_final_summary()

        return self.results

    def _test_regression_hypothesis(self, hyp_id, hyp):
        """Testuje hipotezÄ™ regresyjnÄ…"""

        print(f"\nğŸ”¬ ANALIZA REGRESYJNA - {hyp_id.upper()}")
        print("-" * 40)

        # Przygotowanie danych
        X = self.df[hyp['independent']]
        y = self.df[hyp['dependent']]

        # Podstawowe statystyki
        print(f"ğŸ“Š Statystyki zmiennej zaleÅ¼nej ({hyp['dependent']}):")
        print(f"   Åšrednia: {y.mean():.3f}")
        print(f"   Odchylenie std: {y.std():.3f}")
        print(f"   Zakres: [{y.min():.3f}, {y.max():.3f}]")

        # Korelacje
        print(f"\nğŸ”— Korelacje z zmiennÄ… zaleÅ¼nÄ…:")
        correlations = {}
        for var in hyp['independent']:
            corr, p_val = pearsonr(self.df[var], y)
            correlations[var] = {'correlation': corr, 'p_value': p_val}
            significance = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'
            print(f"   {var}: r = {corr:.3f} (p = {p_val:.4f}) {significance}")

        # Model regresji liniowej
        print(f"\nğŸ“ˆ MODEL REGRESJI LINIOWEJ:")

        # PodziaÅ‚ danych
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

        # Model
        reg_model = LinearRegression()
        reg_model.fit(X_train, y_train)

        # Predykcje
        y_pred_train = reg_model.predict(X_train)
        y_pred_test = reg_model.predict(X_test)

        # Metryki
        r2_train = r2_score(y_train, y_pred_train)
        r2_test = r2_score(y_test, y_pred_test)
        mse_test = np.mean((y_test - y_pred_test) ** 2)
        rmse_test = np.sqrt(mse_test)

        print(f"   RÂ² (treningowy): {r2_train:.3f}")
        print(f"   RÂ² (testowy): {r2_test:.3f}")
        print(f"   RMSE (testowy): {rmse_test:.3f}")

        # WspÃ³Å‚czynniki
        print(f"\nğŸ“Š WspÃ³Å‚czynniki regresji:")
        print(f"   Wyraz wolny: {reg_model.intercept_:.3f}")
        for i, var in enumerate(hyp['independent']):
            coef = reg_model.coef_[i]
            print(f"   {var}: {coef:.3f}")

        # Test istotnoÅ›ci modelu (F-test)
        n = len(y_train)
        k = len(hyp['independent'])

        if r2_train < 1.0:  # Unikamy dzielenia przez zero
            f_statistic = (r2_train / k) / ((1 - r2_train) / (n - k - 1))
            f_p_value = 1 - stats.f.cdf(f_statistic, k, n - k - 1)

            print(f"\nğŸ”¬ Test istotnoÅ›ci modelu (F-test):")
            print(f"   F-statystyka: {f_statistic:.3f}")
            print(f"   p-value: {f_p_value:.6f}")
            print(f"   Model {'ISTOTNY' if f_p_value < 0.05 else 'NIEISTOTNY'} statystycznie (Î±=0.05)")

        # Interpretacja wynikÃ³w
        interpretation = self._interpret_regression_results(r2_test, correlations, hyp['dependent'])

        return {
            'type': 'regression',
            'correlations': correlations,
            'r2_train': r2_train,
            'r2_test': r2_test,
            'rmse': rmse_test,
            'coefficients': dict(zip(['intercept'] + hyp['independent'],
                                     [reg_model.intercept_] + list(reg_model.coef_))),
            'f_statistic': f_statistic if 'f_statistic' in locals() else None,
            'f_p_value': f_p_value if 'f_p_value' in locals() else None,
            'interpretation': interpretation,
            'model': reg_model
        }

    def _test_classification_hypothesis(self, hyp_id, hyp):
        """Testuje hipotezÄ™ klasyfikacyjnÄ…"""

        print(f"\nğŸ”¬ ANALIZA KLASYFIKACYJNA - {hyp_id.upper()}")
        print("-" * 40)

        # Przygotowanie danych
        X = self.df[hyp['independent']]
        y = self.df[hyp['dependent']]

        # Podstawowe statystyki
        class_counts = y.value_counts()
        print(f"ğŸ“Š RozkÅ‚ad klasy docelowej:")
        print(f"   Klasa 0 (Negative): {class_counts[0]} ({class_counts[0]/len(y)*100:.1f}%)")
        print(f"   Klasa 1 (Positive): {class_counts[1]} ({class_counts[1]/len(y)*100:.1f}%)")

        # Korelacje z klasÄ… docelowÄ…
        print(f"\nğŸ”— Korelacje z klasÄ… docelowÄ…:")
        correlations = {}
        for var in hyp['independent']:
            corr, p_val = pearsonr(self.df[var], y)
            correlations[var] = {'correlation': corr, 'p_value': p_val}
            significance = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else 'ns'
            print(f"   {var}: r = {corr:.3f} (p = {p_val:.4f}) {significance}")

        # PodziaÅ‚ danych
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,
                                                            random_state=42, stratify=y)

        # Standaryzacja
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # Model regresji logistycznej
        print(f"\nğŸ“ˆ MODEL REGRESJI LOGISTYCZNEJ:")

        log_model = LogisticRegression(random_state=42)
        log_model.fit(X_train_scaled, y_train)

        # Predykcje
        y_pred = log_model.predict(X_test_scaled)
        y_proba = log_model.predict_proba(X_test_scaled)[:, 1]

        # Metryki
        accuracy = accuracy_score(y_test, y_pred)
        auc = roc_auc_score(y_test, y_proba)

        print(f"   DokÅ‚adnoÅ›Ä‡: {accuracy:.3f}")
        print(f"   AUC: {auc:.3f}")

        # WspÃ³Å‚czynniki
        print(f"\nğŸ“Š WspÃ³Å‚czynniki regresji logistycznej:")
        print(f"   Wyraz wolny: {log_model.intercept_[0]:.3f}")
        for i, var in enumerate(hyp['independent']):
            coef = log_model.coef_[0][i]
            odds_ratio = np.exp(coef)
            print(f"   {var}: {coef:.3f} (OR = {odds_ratio:.3f})")

        # Raport klasyfikacji
        print(f"\nğŸ“‹ RAPORT KLASYFIKACJI:")
        print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))

        # Interpretacja wynikÃ³w
        interpretation = self._interpret_classification_results(accuracy, auc, correlations)

        return {
            'type': 'classification',
            'correlations': correlations,
            'accuracy': accuracy,
            'auc': auc,
            'coefficients': dict(zip(['intercept'] + hyp['independent'],
                                     [log_model.intercept_[0]] + list(log_model.coef_[0]))),
            'odds_ratios': dict(zip(hyp['independent'], np.exp(log_model.coef_[0]))),
            'classification_report': classification_report(y_test, y_pred, target_names=['Negative', 'Positive'], output_dict=True),
            'interpretation': interpretation,
            'model': log_model,
            'scaler': scaler
        }

    def _interpret_regression_results(self, r2, correlations, dependent_var):
        """Interpretuje wyniki analizy regresyjnej"""

        # SiÅ‚a modelu
        if r2 < 0.1:
            model_strength = "bardzo sÅ‚aby"
        elif r2 < 0.3:
            model_strength = "sÅ‚aby"
        elif r2 < 0.5:
            model_strength = "umiarkowany"
        elif r2 < 0.7:
            model_strength = "silny"
        else:
            model_strength = "bardzo silny"

        # Najsilniejszy predyktor
        strongest_predictor = max(correlations.keys(),
                                  key=lambda x: abs(correlations[x]['correlation']))
        strongest_corr = correlations[strongest_predictor]['correlation']

        return {
            'model_strength': model_strength,
            'r2_interpretation': f"Model wyjaÅ›nia {r2*100:.1f}% wariancji {dependent_var}",
            'strongest_predictor': strongest_predictor,
            'strongest_correlation': strongest_corr,
            'conclusion': f"Model ma {model_strength} wpÅ‚yw predykcyjny. "
                          f"Najsilniejszym predyktorem jest {strongest_predictor} (r={strongest_corr:.3f})"
        }

    def _interpret_classification_results(self, accuracy, auc, correlations):
        """Interpretuje wyniki analizy klasyfikacyjnej"""

        # JakoÅ›Ä‡ klasyfikacji na podstawie AUC
        if auc < 0.6:
            model_quality = "bardzo sÅ‚aba"
        elif auc < 0.7:
            model_quality = "sÅ‚aba"
        elif auc < 0.8:
            model_quality = "dobra"
        elif auc < 0.9:
            model_quality = "bardzo dobra"
        else:
            model_quality = "doskonaÅ‚a"

        # Najsilniejszy predyktor
        strongest_predictor = max(correlations.keys(),
                                  key=lambda x: abs(correlations[x]['correlation']))
        strongest_corr = correlations[strongest_predictor]['correlation']

        return {
            'model_quality': model_quality,
            'auc_interpretation': f"AUC = {auc:.3f} wskazuje na {model_quality} zdolnoÅ›Ä‡ predykcyjnÄ…",
            'accuracy_interpretation': f"DokÅ‚adnoÅ›Ä‡ {accuracy*100:.1f}% oznacza poprawnÄ… klasyfikacjÄ™",
            'strongest_predictor': strongest_predictor,
            'strongest_correlation': strongest_corr,
            'conclusion': f"Model ma {model_quality} zdolnoÅ›Ä‡ predykcyjnÄ…. "
                          f"Najsilniejszym predyktorem jest {strongest_predictor} (r={strongest_corr:.3f})"
        }

    def _display_hypothesis_results(self, hyp_id, result):
        """WyÅ›wietla wyniki testowania hipotezy"""

        print(f"\nğŸ’¡ INTERPRETACJA WYNIKÃ“W - {hyp_id.upper()}:")
        print("-" * 50)

        interp = result['interpretation']
        print(f"ğŸ“Š {interp['conclusion']}")

        if result['type'] == 'regression':
            print(f"ğŸ“ˆ {interp['r2_interpretation']}")
            print(f"ğŸ¯ Model ma {interp['model_strength']} wpÅ‚yw predykcyjny")

            # Wnioski o hipotezie
            r2 = result['r2_test']
            if r2 > 0.1 and any(abs(corr['correlation']) > 0.3 for corr in result['correlations'].values()):
                conclusion = "HIPOTEZA POTWIERDZONA CZÄ˜ÅšCIOWO"
                explanation = f"Model wykazuje {interp['model_strength']} zwiÄ…zek predykcyjny"
            elif r2 > 0.05:
                conclusion = "HIPOTEZA POTWIERDZONA SÅABO"
                explanation = "Istnieje sÅ‚aby zwiÄ…zek, ale wymaga dalszych badaÅ„"
            else:
                conclusion = "HIPOTEZA ODRZUCONA"
                explanation = "Brak znaczÄ…cego zwiÄ…zku predykcyjnego"

        else:  # classification
            print(f"ğŸ¯ {interp['auc_interpretation']}")
            print(f"âœ… {interp['accuracy_interpretation']}")

            # Wnioski o hipotezie
            auc = result['auc']
            accuracy = result['accuracy']
            if auc > 0.7 and accuracy > 0.7:
                conclusion = "HIPOTEZA POTWIERDZONA"
                explanation = f"Model ma {interp['model_quality']} zdolnoÅ›Ä‡ predykcyjnÄ…"
            elif auc > 0.6:
                conclusion = "HIPOTEZA POTWIERDZONA CZÄ˜ÅšCIOWO"
                explanation = "Model wykazuje umiarkowanÄ… zdolnoÅ›Ä‡ predykcyjnÄ…"
            else:
                conclusion = "HIPOTEZA ODRZUCONA"
                explanation = "Brak wystarczajÄ…cej zdolnoÅ›ci predykcyjnej"

        print(f"\nğŸ† WNIOSEK: {conclusion}")
        print(f"ğŸ“ UZASADNIENIE: {explanation}")

        # Dodaj do wynikÃ³w
        result['hypothesis_conclusion'] = conclusion
        result['hypothesis_explanation'] = explanation

    def _create_final_summary(self):
        """Tworzy podsumowanie wszystkich hipotez"""

        print(f"\n\n" + "="*80)
        print("PODSUMOWANIE TESTOWANIA HIPOTEZ")
        print("="*80)

        print(f"\nğŸ“‹ STATUS HIPOTEZ:")
        for hyp_id in ['h1', 'h2', 'h3']:
            hyp = self.hypotheses[hyp_id]
            result = self.results[hyp_id]

            status_icon = "âœ…" if "POTWIERDZONA" in result['hypothesis_conclusion'] else "âŒ"
            print(f"{status_icon} {hyp_id.upper()}: {result['hypothesis_conclusion']}")
            print(f"   ğŸ“Œ {hyp['title']}")
            print(f"   ğŸ“Š {result['hypothesis_explanation']}")

            if result['type'] == 'regression':
                print(f"   ğŸ“ˆ RÂ² = {result['r2_test']:.3f}")
            else:
                print(f"   ğŸ“ˆ AUC = {result['auc']:.3f}, Accuracy = {result['accuracy']:.3f}")
            print()

        # Ranking predyktorÃ³w
        print(f"ğŸ† RANKING NAJSILNIEJSZYCH PREDYKTORÃ“W:")
        all_predictors = []

        for hyp_id, result in self.results.items():
            interp = result['interpretation']
            predictor = interp['strongest_predictor']
            strength = abs(interp['strongest_correlation'])
            all_predictors.append((predictor, strength, hyp_id))

        all_predictors.sort(key=lambda x: x[1], reverse=True)

        for i, (predictor, strength, hyp_id) in enumerate(all_predictors, 1):
            print(f"   {i}. {predictor}: |r| = {strength:.3f} (z hipotezy {hyp_id.upper()})")

        # OgÃ³lne wnioski
        confirmed_hypotheses = sum(1 for result in self.results.values()
                                   if "POTWIERDZONA" in result['hypothesis_conclusion'])

        print(f"\nğŸ“Š STATYSTYKI OGÃ“LNE:")
        print(f"   Potwierdzone hipotezy: {confirmed_hypotheses}/3")
        print(f"   Procent sukcesu: {confirmed_hypotheses/3*100:.1f}%")

        if confirmed_hypotheses >= 2:
            overall_conclusion = "Badanie wykazaÅ‚o silne zwiÄ…zki w analizowanych danych medycznych"
        elif confirmed_hypotheses == 1:
            overall_conclusion = "Badanie wykazaÅ‚o czÄ™Å›ciowe zwiÄ…zki - wymaga dalszej analizy"
        else:
            overall_conclusion = "Badanie nie wykazaÅ‚o znaczÄ…cych zwiÄ…zkÃ³w - konieczna reanaliza"

        print(f"\nğŸ¯ WNIOSEK OGÃ“LNY:")
        print(f"   {overall_conclusion}")

    def get_detailed_results(self):
        """Zwraca szczegÃ³Å‚owe wyniki wszystkich testÃ³w"""
        return {
            'hypotheses_definitions': self.hypotheses,
            'test_results': self.results,
            'summary': {
                'confirmed_count': sum(1 for result in self.results.values()
                                       if "POTWIERDZONA" in result['hypothesis_conclusion']),
                'total_count': len(self.results)
            }
        }